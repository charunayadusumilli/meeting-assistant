# Meeting Assistant Backend Configuration
# Copy this file to .env and configure

PORT=3000
BASE_URL=http://localhost:3000

# === LLM Configuration ===
# Provider: 'gemini' (FREE - 1000/day) or 'ollama' (local)
LLM_PROVIDER=gemini
LLM_MODEL=gemini-2.0-flash

# Gemini API Key (optional - CLI uses OAuth by default)
# Get key from: https://aistudio.google.com/apikey
GEMINI_API_KEY=gen-lang-client-0828223009

# Ollama settings (only if LLM_PROVIDER=ollama)
# LLM_BASE_URL=http://localhost:11434
# LLM_MODEL=llama3.2:3b
EMBEDDING_MODEL=nomic-embed-text

# === Speech-to-Text Configuration ===
# Primary: Web Speech API (free, handled in frontend)
# Fallback: Deepgram (optional, requires API key)
DEEPGRAM_API_KEY=Nova3: 21070d40245dae3a113e0699e440fdb49256c3c3
# Get key from: https://console.deepgram.com

# === RAG Configuration ===
TOP_K=5
RERANK_WEIGHT=0.25
CHUNK_SIZE=800
CHUNK_OVERLAP=120
TRANSCRIPT_SCAN_INTERVAL=30000

# === Optional: Qdrant Vector DB ===
# Uncomment to use Qdrant instead of JSON file storage
# QDRANT_URL=http://localhost:6333
# QDRANT_COLLECTION=meeting_assistant

# === Optional: Local Reranker ===
# Improves search quality, requires Python reranker service
# RERANKER_URL=http://localhost:8001
# RERANKER_MODEL=BAAI/bge-reranker-base
