# Meeting Assistant Backend - Configuration Template
# Copy this file to .env and fill in your values

# === Server Configuration ===
PORT=3000
BASE_URL=http://localhost:3000

# === LLM Provider ===
# Options: "anthropic" (Claude), "gemini" (free tier), "openai" (paid), "ollama" (free, local)
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-5-sonnet-20241022

# === Anthropic Claude API (RECOMMENDED) ===
# Get API key from: https://console.anthropic.com/
# New accounts get $5 free credit
ANTHROPIC_API_KEY=

# === Gemini API (FREE TIER) ===
# Get your free API key from: https://aistudio.google.com/apikey
# Free tier: 15 requests/minute, 1500 requests/day
# GEMINI_API_KEY=

# === OpenAI (Optional - PAID) ===
# OPENAI_API_KEY=
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4o-mini

# === Ollama (FREE LOCAL) ===
# For unlimited local usage without API costs
# Install from: https://ollama.com/download
# LLM_BASE_URL=http://localhost:11434
# LLM_MODEL=llama3.2:3b
# EMBEDDING_MODEL=nomic-embed-text

# === Vector Store ===
VECTOR_BACKEND=json

# === Speech-to-Text (FREE) ===
# Leave empty to use Web Speech API (100% free)
# DEEPGRAM_API_KEY=

# === RAG Configuration ===
TOP_K=5
RERANK_WEIGHT=0.25
CHUNK_SIZE=800
CHUNK_OVERLAP=120

# === Auto-Detect ===
AUTO_DETECT_ENABLED=true
AUTO_DETECT_COOLDOWN=15000

NODE_ENV=production
